# -*- coding: utf-8 -*-
"""KmeanCLustering.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wFEN9vNXwo2yOqovNWLEaLJ8t_n5-qgd
"""

import pickle
from yellowbrick.model_selection import LearningCurve
from sklearn.cluster import KMeans
from geopy.geocoders import Nominatim
import numpy as np
import pandas as pd
import warnings
from yellowbrick.cluster import SilhouetteVisualizer, KElbowVisualizer
import matplotlib.pyplot as plt
from matplotlib import style
from sklearn.metrics import silhouette_score
warnings.filterwarnings('ignore')

df = pd.read_csv('Hotel_data.csv', encoding='cp1252')
df['price'] = df['price'].astype('str').str.extractall(
    '(\d+)').unstack().fillna('').sum(axis=1).astype(int)
df = df[['Title', 'City', 'price', 'Special', 'Discount', 'Rating']]
df = df.sort_values(by='Rating', ascending=False)
df = df.sort_values(by='price', ascending=False)
bin = [0, 1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000]
rating_bin = [0, 1, 2, 3, 4, 5]
df['rating_bin'] = pd.cut(df['Rating'], rating_bin)
df['price_bin'] = pd.cut(df['price'], bin)
#df = df.iloc[:101,:]
df.head(5)
city = df['City'].unique()
print(city)

geolocator = Nominatim(user_agent="specify")

lang, latt, cit = [], [], []

for c in city:
    location = geolocator.geocode(c+',India')
    if location is not None:
        lang.append(location.longitude)
        latt.append(location.latitude)
        cit.append(c)

dframe = {"longitude": lang, "latitude": latt}

loct = pd.DataFrame(dframe)
loct.head()
kmean = KMeans(20)
kmean.fit(loct)

idx_cluster = list(kmean.fit_predict(loct))
loct['Cluster_ind'] = idx_cluster
loct['City'] = cit
df = pd.merge(df, loct, on="City")
#ra = np.random.randint(0,2000,size=(8014, 1))
#df['uID'] = ra
df.head()

plt.scatter(lang, latt)
loct1 = pd.DataFrame(dframe)
kmeans1 = KMeans(n_clusters=20)
kmeans1.fit(loct1)
cluster_labels = kmeans1.labels_
s = silhouette_score(loct1, cluster_labels)
print(s)
visualizer1 = SilhouetteVisualizer(kmeans1, colors='yellowbrick')
visualizer2 = KElbowVisualizer(kmeans1, k=(4, 12))
visualizer3 = LearningCurve(
    kmeans1, scoring="adjusted_rand_score", random_state=42)
visualizer1.fit(loct1)        # Fit the data to the visualizer
visualizer1.show()


def result(inputCity, price, rating):
    #inputCity = input("Enter a city: ")
    #price = input("Enter a price: ")
    lo = geolocator.geocode(inputCity+',India')
    o = kmean.predict(pd.DataFrame(
        {"longitude": [lo.longitude], "latitude": [lo.latitude]}))

    clust = o[0]
    opCities = df.loc[df['Cluster_ind'] == clust, [
        'Title', 'City', 'price', 'Special', 'Discount', 'Rating', 'price_bin', 'rating_bin']]
    # print(opCities)
    p = pd.cut([int(price)], bin)
    r = pd.cut([int(rating)], rating_bin)
    op = opCities.loc[opCities['price_bin'] == p[0], [
        'Title', 'City', 'price', 'Special', 'Discount', 'Rating', 'rating_bin']]
    res = op.loc[op['rating_bin'] == r[0], [
        'Title', 'City', 'price', 'Special', 'Discount', 'Rating']]
    res = res.reset_index()
    res.dropna()
    res.head(5)
    return res.head(5)


pickle.dump(kmean, open('kmeans.sav', 'wb'))
df.to_pickle("df.pkl")
result('Bhusaval', 5000, 4)



#from scipy.sparse import csr_matrix
#ratingPivot = opCities[['uID','id','Rating']].pivot(index="id",columns="uID",values="Rating").fillna(0)
#ratingMatrix = csr_matrix(ratingPivot.values)

#from sklearn.neighbors import NearestNeighbors

#knn = NearestNeighbors(metric="cosine",algorithm="brute",n_neighbors=20)
# knn.fit(ratingMatrix)

#!pip install fuzzywuzzy
#from fuzzywuzzy import process
# def recomm(Title,d,model,n):

#  model.fit(d)
#  idx = process.extractOne(Title,opCities['City'])[2]
#  d, ind = model.kneighbors(d[idx],n_neighbors=n)
#  print("Title    City")
#  for i in ind:
#    print(opCities['City'][i].where(i!=[idx]).dropna()+"    "+opCities['Title'][i].where(i!=[idx]).dropna())

# recomm(inputCity,ratingMatrix,knn,7)
